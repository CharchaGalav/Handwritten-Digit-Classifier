{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Charcha\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_img(i):\n",
    "    plt.imshow(X_train[i], cmap='binary')\n",
    "    plt.title(y_train[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_input_img(9)\n",
    "plot_input_img(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0 189 190   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 143 247 153   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 136 247 242  86   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 192 252 187   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  62 185  18   0   0   0\n",
      "    0  89 236 217  47   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 216 253  60   0   0   0\n",
      "    0 212 255  81   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 206 252  68   0   0   0\n",
      "   48 242 253  89   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 131 251 212  21   0   0  11\n",
      "  167 252 197   5   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  29 232 247  63   0   0   0 153\n",
      "  252 226   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  45 219 252 143   0   0   0 116 249\n",
      "  252 103   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   4  96 253 255 253 200 122   7  25 201 250\n",
      "  158   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  92 252 252 253 217 252 252 200 227 252 231\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  87 251 247 231  65  48 189 252 252 253 252 251\n",
      "  227  35   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 190 221  98   0   0   0  42 196 252 253 252 252\n",
      "  162   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 111  29   0   0   0   0  62 239 252  86  42  42\n",
      "   14   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  15 148 253 218   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 121 252 231  28   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  31 221 251 129   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 218 252 160   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 122 252  82   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[9]) #checking the pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizinng the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22078dc4160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gray sacle image so pixel values are between 0 and 255 \n",
    "# we need to normalize the data to be between 0 and 1\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1) # or X_train = X_train/255\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "plt.imshow(X_train[9], cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.43080231 0.73455499\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.31464079 0.5630062  0.59151007\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25752265 0.54347046 0.55160931 0.33248279\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.36356139 0.55447189 0.42624356 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08263281 0.2424802  0.03354929 0.         0.         0.\n",
      "  0.         0.18249242 0.44687754 0.4774619  0.10713073 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.28788206 0.33160806 0.11183097 0.         0.         0.\n",
      "  0.         0.43470103 0.48285497 0.17822311 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27455418 0.33029736 0.12674177 0.         0.         0.\n",
      "  0.0941115  0.49621533 0.47906787 0.19582539 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.19780352\n",
      "  0.33452961 0.27786921 0.03914084 0.         0.         0.01915839\n",
      "  0.32742958 0.5167201  0.37302913 0.01100143 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.0585375  0.35030852\n",
      "  0.32919846 0.08257434 0.         0.         0.         0.26647572\n",
      "  0.49408535 0.46340771 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.10522207 0.44205906 0.38050753\n",
      "  0.19058858 0.         0.         0.         0.23381538 0.43367617\n",
      "  0.49408535 0.21119909 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01149145 0.25357016 0.59158187 0.5147263  0.38201748\n",
      "  0.26655746 0.15990586 0.01304695 0.05772456 0.40514561 0.43541784\n",
      "  0.30978367 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26430344 0.66562166 0.5892436  0.51068923 0.32765926\n",
      "  0.3358624  0.33029736 0.37276991 0.52413901 0.50794375 0.40232609\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.36767493 0.72108874 0.65241488 0.54013997 0.13120474 0.07247762\n",
      "  0.2518968  0.33029736 0.46969008 0.58417255 0.50794375 0.43715952\n",
      "  0.44506895 0.07176668 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.80296824 0.63490283 0.25885287 0.         0.         0.\n",
      "  0.05597707 0.25689794 0.46969008 0.58417255 0.50794375 0.43890119\n",
      "  0.3176263  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.4691025  0.08331304 0.         0.         0.         0.\n",
      "  0.08263281 0.31325821 0.46969008 0.19857249 0.08465729 0.0731502\n",
      "  0.02744919 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.02264926\n",
      "  0.19725252 0.33160806 0.4063192  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18270401\n",
      "  0.3358624  0.30277258 0.05218779 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.06257457 0.33369906\n",
      "  0.33452961 0.16908079 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.44004052 0.38050753\n",
      "  0.21324597 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.24626121 0.38050753\n",
      "  0.10928856 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[9]) #checking the pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples dimension: (60000, 28, 28, 1)\n",
      "Testing samples dimension: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "img_size = 28\n",
    "# Reshaping the data from 28x28 to 28x28x1 to fit the input dimensions in Conv2D layer in keras\n",
    "# 1 for grayscale and 3 for RGB\n",
    "X_trainr = np.array(X_train).reshape(-1, img_size, img_size, 1) \n",
    "X_testr = np.array(X_test).reshape(-1, img_size, img_size, 1)\n",
    "print(\"Training samples dimension:\", X_trainr.shape)\n",
    "print(\"Testing samples dimension:\", X_testr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Deep Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=X_trainr.shape[1:], activation='relu')) # what is convo2D -> it is a layer that extracts features from a source image. These features are commonly learned by sliding a convolutional kernel (filter) across the input image.\n",
    "model.add(MaxPooling2D((2,2))) # what is MaxPooling2D -> it is a technique used to reduce the number of parameters in our model by downsampling the feature maps.\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu')) # what is relu -> it is an activation function that is used to increase the non-linearity in our model. It is an element-wise operation (applied per pixel) and replaces all negative pixel values in the feature map by zero.\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #max pooling is used to reduce the spatial dimensions of a given image.\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu')) \n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "# Flatten the layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(64, 'relu')) # what is Dense -> it is a fully connected layer. It is used to connect all neurons in one layer to every neuron in the next layer.\n",
    "\n",
    "# Dropout layer\n",
    "model.add(Dropout(0.25)) # it is regularization technique that prevents overfitting\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81066 (316.66 KB)\n",
      "Trainable params: 81066 (316.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', min_delta=0.01, patience=4, verbose=1 )\n",
    "mc = ModelCheckpoint('./best_model.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8668WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 44s 31ms/step - loss: 0.4208 - accuracy: 0.8668 - val_loss: 0.1366 - val_accuracy: 0.9576\n",
      "Epoch 2/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9603WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.1327 - accuracy: 0.9603 - val_loss: 0.0902 - val_accuracy: 0.9727\n",
      "Epoch 3/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9709WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 26ms/step - loss: 0.0975 - accuracy: 0.9709 - val_loss: 0.0737 - val_accuracy: 0.9775\n",
      "Epoch 4/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9777WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 43s 32ms/step - loss: 0.0748 - accuracy: 0.9777 - val_loss: 0.0702 - val_accuracy: 0.9785\n",
      "Epoch 5/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9821WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 40s 30ms/step - loss: 0.0612 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9806\n",
      "Epoch 6/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9843WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.0525 - accuracy: 0.9843 - val_loss: 0.0655 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9864WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.0635 - val_accuracy: 0.9815\n",
      "Epoch 8/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9882WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.0383 - accuracy: 0.9882 - val_loss: 0.0623 - val_accuracy: 0.9822\n",
      "Epoch 9/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9896WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 0.0618 - val_accuracy: 0.9823\n",
      "Epoch 10/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9903WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.0586 - val_accuracy: 0.9844\n",
      "Epoch 11/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9918WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0584 - val_accuracy: 0.9847\n",
      "Epoch 12/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9924WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0603 - val_accuracy: 0.9851\n",
      "Epoch 13/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9927WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0581 - val_accuracy: 0.9851\n",
      "Epoch 14/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9939WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0586 - val_accuracy: 0.9850\n",
      "Epoch 15/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9942WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.0891 - val_accuracy: 0.9822\n",
      "Epoch 16/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9945WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0697 - val_accuracy: 0.9839\n",
      "Epoch 17/50\n",
      "1310/1313 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9947WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0756 - val_accuracy: 0.9845\n",
      "Epoch 18/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9954WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0718 - val_accuracy: 0.9852\n",
      "Epoch 19/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9951WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0699 - val_accuracy: 0.9848\n",
      "Epoch 20/50\n",
      "1310/1313 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9961WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 26ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0678 - val_accuracy: 0.9859\n",
      "Epoch 21/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9964WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0766 - val_accuracy: 0.9848\n",
      "Epoch 22/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9962WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 44s 33ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0850 - val_accuracy: 0.9842\n",
      "Epoch 23/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9963WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 43s 33ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0772 - val_accuracy: 0.9836\n",
      "Epoch 24/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9967WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0925 - val_accuracy: 0.9836\n",
      "Epoch 25/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9967WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 26ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0757 - val_accuracy: 0.9847\n",
      "Epoch 26/50\n",
      "1310/1313 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 38s 29ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0893 - val_accuracy: 0.9846\n",
      "Epoch 27/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0812 - val_accuracy: 0.9862\n",
      "Epoch 28/50\n",
      "1310/1313 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9974WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 26ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0887 - val_accuracy: 0.9844\n",
      "Epoch 29/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9962WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0908 - val_accuracy: 0.9853\n",
      "Epoch 30/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9972WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 38s 29ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0844 - val_accuracy: 0.9843\n",
      "Epoch 31/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0879 - val_accuracy: 0.9859\n",
      "Epoch 32/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9972WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0896 - val_accuracy: 0.9853\n",
      "Epoch 33/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0917 - val_accuracy: 0.9859\n",
      "Epoch 34/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9965WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0896 - val_accuracy: 0.9836\n",
      "Epoch 35/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0949 - val_accuracy: 0.9854\n",
      "Epoch 36/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0938 - val_accuracy: 0.9853\n",
      "Epoch 37/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9975WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0986 - val_accuracy: 0.9841\n",
      "Epoch 38/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0930 - val_accuracy: 0.9859\n",
      "Epoch 39/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9976WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0952 - val_accuracy: 0.9850\n",
      "Epoch 40/50\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9975WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0850 - val_accuracy: 0.9870\n",
      "Epoch 41/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1085 - val_accuracy: 0.9857\n",
      "Epoch 42/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9975WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0993 - val_accuracy: 0.9846\n",
      "Epoch 43/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 28ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0821 - val_accuracy: 0.9872\n",
      "Epoch 44/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0976 - val_accuracy: 0.9857\n",
      "Epoch 45/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 35s 27ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0997 - val_accuracy: 0.9854\n",
      "Epoch 46/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9977WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1243 - val_accuracy: 0.9803\n",
      "Epoch 47/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9981WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0900 - val_accuracy: 0.9861\n",
      "Epoch 48/50\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1133 - val_accuracy: 0.9838\n",
      "Epoch 49/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9977WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1150 - val_accuracy: 0.9844\n",
      "Epoch 50/50\n",
      "1311/1313 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9977WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 36s 27ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0926 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2207e344040>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs= 50, validation_split=0.3, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Charcha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('best_model', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S = keras.models.load_model('C:/Users/Charcha/Music/ML/HandwrittenDigit/handwrittenDigit/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0945 - accuracy: 0.9861\n",
      "Model Accuracy = 0.9861000180244446\n"
     ]
    }
   ],
   "source": [
    "score = model_S.evaluate(X_test, y_test) \n",
    "print(f'Model Accuracy = {score[1]}') # score[0] is loss and score[1] is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
